{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7a9af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'   \n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d02d9e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([12, 15, 18, 21])\n",
      "tensor([ 6, 22, 38])\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n"
     ]
    }
   ],
   "source": [
    "#利用torch进行多维张量的求和操作\n",
    "#torch.sum(input, dim, keepdim=False, dtype=None) -> Tensor\n",
    "a=torch.arange(12).reshape(3,4)\n",
    "print(a)\n",
    "a_sum_0=a.sum(dim=0)\n",
    "a_sum_1=a.sum(dim=1)\n",
    "print(a_sum_0)\n",
    "print(a_sum_1)\n",
    "try:\n",
    "    a_sum_2=a.sum(dim=2)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2ad97a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#利用torch进行矩阵的向量机乘\n",
    "b=torch.ones(3,4,dtype=torch.float32)\n",
    "print(b)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e98c872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7321, 1.7321, 1.7321, 1.7321])\n",
      "tensor([2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "#计算范式\n",
    "c_0=torch.norm(b,dim=0)\n",
    "print(c_0)\n",
    "c_1=torch.norm(b,dim=1)\n",
    "print(c_1)\n",
    "#整体上计算遵循的是列向量为0，行向量为1的原则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d640549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n",
      "tensor(6.)\n",
      "tensor([2.4495, 2.4495, 2.4495, 2.4495, 2.4495, 2.4495])\n",
      "tensor([2.4495, 2.4495, 2.4495, 2.4495, 2.4495, 2.4495])\n"
     ]
    }
   ],
   "source": [
    "#什么是范数呢\n",
    "#范数是一个标量，用于表示向量或矩阵的大小或长度。\n",
    "#在torch中，范数的计算可以使用torch.norm()函数实现。\n",
    "#torch.norm(input, p='fro', dim=None, keepdim=False, dtype=None) -> Tensor\n",
    "#其中，p参数指定范数的类型，dim参数指定计算范数的维\n",
    "#度，keepdim参数指定是否保持维度不变，dtype参数指定输出的类型。\n",
    "#矩阵的弗罗贝乌斯范数（Frobenius norm）是矩阵元素的平方和的平方根。\n",
    "#它是矩阵的一个重要性质，常用于衡量矩阵的大小或复杂度。\n",
    "#弗罗贝乌斯范数可以通过torch.norm()函数计算，默认情况下p='fro'。\n",
    "print(torch.ones(6,6))\n",
    "print(torch.norm(torch.ones(6,6)))\n",
    "print(torch.norm(torch.ones(6,6),dim=0))\n",
    "print(torch.norm(torch.ones(6,6),dim=1))\n",
    "#torch.norm(torch.ones(6,6),p=1)\n",
    "#torch.norm(torch.ones(6,6),p=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad641860",
   "metadata": {},
   "source": [
    "#对于多个矩阵维度的sum的理解\n",
    "#torch.sum(input, dim, keepdim=False, dtype=None) -> Tensor\n",
    "对于一个维度为[5,4]的矩阵\n",
    "当dim=0时，我是在遍历所有的矩阵行，留下的是一个矩阵的列，即[4]\n",
    "当dim=1时，我正在遍历所有的矩阵列，留下一个矩阵的行，即[5]\n",
    "按照某一个维度进行矩阵运算求和，便留下了一个新的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caeb938b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "torch.Size([2, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "a=torch.ones((2,5,4))\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c80f527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4])\n",
      "tensor([[5., 5., 5., 5.],\n",
      "        [5., 5., 5., 5.]])\n",
      "torch.Size([2, 4])\n",
      "tensor([[[4.],\n",
      "         [4.],\n",
      "         [4.],\n",
      "         [4.],\n",
      "         [4.]],\n",
      "\n",
      "        [[4.],\n",
      "         [4.],\n",
      "         [4.],\n",
      "         [4.],\n",
      "         [4.]]])\n",
      "torch.Size([2, 5, 1])\n"
     ]
    }
   ],
   "source": [
    "b=a.sum(dim=0)\n",
    "print(b.shape)\n",
    "c=a.sum(dim=1)\n",
    "print(c)\n",
    "print(c.shape)\n",
    "d=a.sum(dim=2,keepdim=True)\n",
    "print(d)\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae143b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=2.0\n",
      "y=x**2+2*x+1=9.0\n",
      "dy/dx=6.0\n",
      "导数的理论值大小为:6.0\n"
     ]
    }
   ],
   "source": [
    "#利用torch完成导数的求解\n",
    "x=torch.tensor(2.0,requires_grad=True)\n",
    "y=x**2+2*x+1\n",
    "print(f\"x={x}\")\n",
    "print(f\"y=x**2+2*x+1={y}\")\n",
    "\n",
    "#计算梯度\n",
    "y.backward()\n",
    "print(f\"dy/dx={x.grad}\")\n",
    "print(f\"导数的理论值大小为:6.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8293c87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f=49.0\n",
      "df/dx=14.0\n",
      "df/dy=14.0\n",
      "tensor(True)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "#多变量的函数求导\n",
    "x=torch.tensor(3.0,requires_grad=True)\n",
    "y=torch.tensor(4.0,requires_grad=True)\n",
    "\n",
    "f=x**2+y**2+2*x*y\n",
    "print(f\"f={f}\")\n",
    "\n",
    "#梯度计算 完成反向传播\n",
    "f.backward()\n",
    "print(f\"df/dx={x.grad}\")\n",
    "print(f\"df/dy={y.grad}\")\n",
    "\n",
    "#完成比对理论值与实际值\n",
    "flag1=(x.grad==2*x+2*y)\n",
    "flag2=(y.grad==2*y+2*x)\n",
    "print(flag1)\n",
    "print(flag2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11a2f7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=tensor([-1275.2042,   -43.2743,   442.2977], grad_fn=<MulBackward0>)\n",
      "y的范数为:1350.4241943359375\n",
      "x的梯度: tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n",
      "这里计算的是Jacobian矩阵与向量v的乘积\n",
      "\n",
      "=== 梯度累积与清零 ===\n",
      "第一次反向传播后x.grad = 4.0\n",
      "第二次反向传播后x.grad = 8.0 (注意梯度累积了)\n",
      "清零梯度后再次反向传播x.grad = 4.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#完成高级自动求导\n",
    "x=torch.randn(3,requires_grad=True)\n",
    "y=x*2\n",
    "while y.data.norm()<1000:\n",
    "    y=y*2\n",
    "print(f\"y={y}\")\n",
    "print(f\"y的范数为:{y.data.norm()}\")\n",
    "\n",
    "v=torch.tensor([0.1,1.0,0.0001],dtype=torch.float)\n",
    "y.backward(v)\n",
    "print(f\"x的梯度: {x.grad}\")\n",
    "print(\"这里计算的是Jacobian矩阵与向量v的乘积\\n\")\n",
    "\n",
    "# 零梯度和梯度累积\n",
    "print(\"=== 梯度累积与清零 ===\")\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x ** 2\n",
    "\n",
    "# 第一次反向传播\n",
    "y.backward()\n",
    "print(f\"第一次反向传播后x.grad = {x.grad}\")\n",
    "\n",
    "# 再次计算并反向传播（梯度会累积）\n",
    "y = x ** 2\n",
    "y.backward()\n",
    "print(f\"第二次反向传播后x.grad = {x.grad} (注意梯度累积了)\")\n",
    "\n",
    "# 清零梯度\n",
    "x.grad.zero_()\n",
    "y = x ** 2\n",
    "y.backward()\n",
    "print(f\"清零梯度后再次反向传播x.grad = {x.grad}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf574c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 实际应用：简单线性回归 ===\n",
      "epoch=0\n",
      "真实权重: 3, 学习到的权重: 1.041\n",
      "真实偏置: 2, 学习到的偏置: 0.042\n",
      "epoch=100\n",
      "真实权重: 3, 学习到的权重: 2.754\n",
      "真实偏置: 2, 学习到的偏置: 1.774\n",
      "epoch=200\n",
      "真实权重: 3, 学习到的权重: 2.970\n",
      "真实偏置: 2, 学习到的偏置: 1.977\n",
      "epoch=300\n",
      "真实权重: 3, 学习到的权重: 2.997\n",
      "真实偏置: 2, 学习到的偏置: 2.001\n",
      "epoch=400\n",
      "真实权重: 3, 学习到的权重: 3.001\n",
      "真实偏置: 2, 学习到的偏置: 2.003\n",
      "epoch=500\n",
      "真实权重: 3, 学习到的权重: 3.001\n",
      "真实偏置: 2, 学习到的偏置: 2.004\n",
      "epoch=600\n",
      "真实权重: 3, 学习到的权重: 3.001\n",
      "真实偏置: 2, 学习到的偏置: 2.004\n",
      "epoch=700\n",
      "真实权重: 3, 学习到的权重: 3.001\n",
      "真实偏置: 2, 学习到的偏置: 2.004\n",
      "epoch=800\n",
      "真实权重: 3, 学习到的权重: 3.001\n",
      "真实偏置: 2, 学习到的偏置: 2.004\n",
      "epoch=900\n",
      "真实权重: 3, 学习到的权重: 3.001\n",
      "真实偏置: 2, 学习到的偏置: 2.004\n",
      "训练完成:\n",
      "真实权重: 3, 学习到的权重: 3.001\n",
      "真实偏置: 2, 学习到的偏置: 2.004\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 实际应用：简单线性回归 ===\")\n",
    "# 生成示例数据\n",
    "torch.manual_seed(42)\n",
    "X = torch.randn(100, 1)\n",
    "y_true = 3 * X + 2 + 0.1 * torch.randn(100, 1)  # y = 3x + 2 + noise\n",
    "\n",
    "# 初始化参数\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "b = torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "# 训练过程\n",
    "learning_rate = 0.01\n",
    "for epoch in range(1000):\n",
    "    # 前向传播\n",
    "    y_pred = w * X + b\n",
    "    \n",
    "    # 计算损失 (均方误差)\n",
    "    loss = torch.mean((y_pred - y_true) ** 2)\n",
    "    \n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "    \n",
    "    # 更新参数\n",
    "    with torch.no_grad():  # 不跟踪梯度的更新操作\n",
    "        w -= learning_rate * w.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        \n",
    "        # 清零梯度\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    if epoch %100 ==0:\n",
    "        print(f\"epoch={epoch}\")\n",
    "        print(f\"真实权重: 3, 学习到的权重: {w.item():.3f}\")\n",
    "        print(f\"真实偏置: 2, 学习到的偏置: {b.item():.3f}\")\n",
    "\n",
    "print(f\"训练完成:\")\n",
    "print(f\"真实权重: 3, 学习到的权重: {w.item():.3f}\")\n",
    "print(f\"真实偏置: 2, 学习到的偏置: {b.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c2e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "642fe592",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
